{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/store/tveiga/miniconda3/envs/py/lib/python3.7/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('../data-simplified-1-reduced-wordbal-800.csv')\n",
    "data = pd.read_csv('../data-reduced-800-v3-shuffled.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcode = pd.read_csv('../data-simplified-1-catcode.csv', header = None, names = ['category'])['category'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "      <th>priorities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>473424</th>\n",
       "      <td>Kit 04 Jogo De Lençol De Berço Em Malha 3 Pcs 100% Algodão</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>6245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519083</th>\n",
       "      <td>Bomba Submersa 450 W Agua Suja Turva Limpa Bsv 450 Vonder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1360</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19488607</th>\n",
       "      <td>Nadador Tiburon Ys1378-5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1155</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16895633</th>\n",
       "      <td>Máscara Angry Birds 6un Imbatível</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1102</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10369454</th>\n",
       "      <td>Aparador Fruteira Madeira De Demolição 1 Gaveta Peroba Rosa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1288</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                title  \\\n",
       "473424     Kit 04 Jogo De Lençol De Berço Em Malha 3 Pcs 100% Algodão   \n",
       "7519083     Bomba Submersa 450 W Agua Suja Turva Limpa Bsv 450 Vonder   \n",
       "19488607                                     Nadador Tiburon Ys1378-5   \n",
       "16895633                            Máscara Angry Birds 6un Imbatível   \n",
       "10369454  Aparador Fruteira Madeira De Demolição 1 Gaveta Peroba Rosa   \n",
       "\n",
       "          label_quality  language  category  priorities  \n",
       "473424                0         1       114        6245  \n",
       "7519083               1         1      1360           4  \n",
       "19488607              1         0      1155          54  \n",
       "16895633              0         1      1102         486  \n",
       "10369454              0         1      1288        1075  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(curr):\n",
    "    # remove accent\n",
    "    curr = curr.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    # to lower case\n",
    "    curr = curr.str.lower()\n",
    "    # remove not alphanumerics or . ,\n",
    "    curr = curr.str.replace('[^a-zA-Z0-9.,]', ' ')\n",
    "    \n",
    "    # let , and . be the same char\n",
    "    curr = curr.str.replace('[.]', ',')\n",
    "    \n",
    "    # remove . , not between numbers\n",
    "    curr = curr.str.replace('(?<=[0-9])[,]+(?=[0-9])', '.')\n",
    "    curr = curr.str.replace('[,]', ' ')\n",
    "    \n",
    "    # set all digits to 0\n",
    "    curr = curr.str.replace('[0-9]', '0')\n",
    "    \n",
    "    # separate ' <digits><letters ' like in 22g or 12ms\n",
    "    # curr = curr.str.replace('(^| )([0-9]+)([a-zA-Z]+)($| )', r'\\1\\2 \\3\\4')\n",
    "    \n",
    "    # remove some Pt plurals\n",
    "    curr = curr.str.replace('\\\\b([a-zA-Z]+[aeiouwy])(s)\\\\b', r'\\1')\n",
    "    \n",
    "    # remove 4 consec (same) letters to just one\n",
    "    curr = curr.str.replace(r'([a-zA-Z])\\1{3,}', r'\\1') # 3 is four? -> three of \\1 after first \\1...\n",
    "    \n",
    "    # separate 4 or more consecutive (different or not) letters\n",
    "    curr = curr.str.replace(r'([a-zA-Z]{4,})', r' \\1 ')\n",
    "    \n",
    "    # Other ideas: \n",
    "    \n",
    "    return curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /store/tveiga/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = lambda w : unicodedata.normalize('NFKD', w).encode('ASCII', 'ignore').decode('ASCII')\n",
    "all_stopw = set()\n",
    "for corpus in ['english', 'portuguese', 'spanish']:\n",
    "    all_stopw.update(set(map(norm, stopwords.words(corpus))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = int(len(data) * 0.8) # Split Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.concat([data[['title']], test[['title']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.9 s, sys: 262 ms, total: 30.2 s\n",
      "Wall time: 29.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_full = full.title\n",
    "X_full = normalize(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 s, sys: 716 ms, total: 17.4 s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "wordfreq = X_full.str.split(expand=True).stack().value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102942\n",
      "CPU times: user 32.9 ms, sys: 22 µs, total: 32.9 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "uniquewords = {w for w, f in wordfreq.items() if f == 1}\n",
    "print(len(uniquewords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3906\n"
     ]
    }
   ],
   "source": [
    "testwordfreq = X_full[len(data):].str.split(expand=True).stack().value_counts().to_dict()\n",
    "testuniquewords = {w for w, f in testwordfreq.items() if wordfreq[w] == 1}\n",
    "print(len(testuniquewords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.26 s, sys: 32 ms, total: 4.29 s\n",
      "Wall time: 4.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xremo = lambda s : ' '.join([w for w in s if w not in all_stopw])\n",
    "X_full = X_full.str.split().apply(xremo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.41 s, sys: 16 ms, total: 2.43 s\n",
      "Wall time: 2.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# go full crazy!\n",
    "X_full = X_full.str.split().str.join('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_full = '1' + X_full + '2' #actaully don't need it when joining everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_1gram = X_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 218233) 107500515\n",
      "CPU times: user 1min 39s, sys: 2.72 s, total: 1min 41s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "covec_1gram = CountVectorizer(binary = True, min_df= 50, analyzer = 'char_wb', max_df = .05,\n",
    "                             ngram_range=(4,5),)\n",
    "X_covec_1gram = covec_1gram.fit_transform(X_full)\n",
    "print(X_covec_1gram.shape, X_covec_1gram.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfreq1 = np.array(X_covec_1gram.sum(axis = 0)).flatten() / X_covec_1gram.shape[0]\n",
    "inv_vocab1 = {v : k for k,v in covec_1gram.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mult', 'zador', 'digi', 'lectr', 'ogra', 'acor', 'ific', 'entr',\n",
       "       'inho', 'rico', 'porte', 'ro00', 'rador', 'prof', 'nado', 'grat',\n",
       "       'lumin', 't0000', 'trol', 'capa', 'olor', 'pare', 'eletr', 'etal',\n",
       "       'elect', 'avel', 'onta', 'lant', 'er00', 'itro', 'erta', 'rote',\n",
       "       'umin', '000s', 'nal ', 'reto', 'lumi', '0000c', 'cador', 'bate',\n",
       "       'acion', 'ulti', 'dore', 'raca', 'icad', 'ectr', 'mesa', 'quin',\n",
       "       'auto', 'aqui', 'teria', 'laca', '000x', 'cort', 'amen', 'egra',\n",
       "       'ader', 'ctor', 'p000', 'tador', 'letr', 'bran', 'lanc', 'illo',\n",
       "       'ande', 'otor', '000ml', 'r0000', 'enta', 'ado ', 'ampa', '00un',\n",
       "       'acio', 'elec', '000l', '000b', 'last', 'ional', 'e0000', 'colo',\n",
       "       'metro', 'elet', 'cont', 'unida', ' kit0', '0000m', 'mento',\n",
       "       'amar', '.000', '0.000', 'ster', 'lect', 'pres', 'made', 'anca',\n",
       "       'asti', 'nidad', 'para', 'acao', 'nida', 'pret', 'ital', 'n000',\n",
       "       'rica', 'izado', 's000', 'm000', '0unid', 'd000', 'ranc', 'adeir',\n",
       "       'metr', 'leta', '00ml', 'anco', 'adei', 'c000', 'stic', '000a',\n",
       "       'deira', 'tura', '0uni', 'inha', 'arra', 'lador', 'deir', '000w',\n",
       "       'eiro', 'illa', 'eria', 'idade', 'zado', 'rati', 'sion', 'unid',\n",
       "       'tica', 'nter', 'tric', 'izad', 'teri', '000g', 'onal', 'kit0',\n",
       "       'cado', 'o0000', 'dade', 'inte', 'esta', 'l000', 'tado', '000p',\n",
       "       'tico', 'comp', 'orte', 't000', 'ment', '00mm', 'rado', 'ater',\n",
       "       'etro', 'iona', 'able', '00.0', 'a0000', 'moto', 'ento', 'mini',\n",
       "       'igina', 'ginal', 'rigin', 'igin', 'origi', 'r000', '000c', 'rigi',\n",
       "       'idad', 'anti', 'gina', 'orig', 'e000', 'porta', '00x00', '000v',\n",
       "       '00cm', 'x000', 'lado', 'ente', 'cion', 'adora', 'inal', '0x00',\n",
       "       'dora', '00x0', '0.00', 'ante', 'orta', 'o000', ' kit', 'eira',\n",
       "       '000m'], dtype='<U5')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vectorize(inv_vocab1.get)(np.argsort(docfreq1)[-200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03864361, 0.04064696, 0.04068825, 0.04183813, 0.04289003,\n",
       "       0.04344772, 0.04466415, 0.0464204 , 0.04944114, 0.0496408 ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(docfreq1)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 218233) 107500515\n"
     ]
    }
   ],
   "source": [
    "X_train_counts = X_covec_1gram\n",
    "print(X_train_counts.shape, X_train_counts.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbc(x):\n",
    "    # sparse binary correlation; x : sparse\n",
    "    # can't correlate zero columns\n",
    "    cx = sparse.triu(x.T*x, k = 1, format='coo')\n",
    "    # print(cx.todense())\n",
    "    card = np.array(x.sum(axis = 0)).flatten()\n",
    "    # print(card)\n",
    "    cx.data = cx.data / (card[cx.row] + card[cx.col] - cx.data)\n",
    "    # print(cx.todense())\n",
    "    return np.array((cx == 1).sum(axis = 0) > 0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007546979604367809\n",
      "CPU times: user 3min 23s, sys: 30.9 s, total: 3min 54s\n",
      "Wall time: 4min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rem = sbc(X_train_counts)\n",
    "print(rem.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 216586) 107036608\n"
     ]
    }
   ],
   "source": [
    "X_train_counts = X_train_counts[:, ~rem]\n",
    "print(X_train_counts.shape, X_train_counts.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_go = X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 216586)\n",
      "CPU times: user 1.11 s, sys: 224 ms, total: 1.33 s\n",
      "Wall time: 654 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(norm='l2', use_idf=False, smooth_idf=True, sublinear_tf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_go = X_train_tfidf\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1100658, 216586), (275165, 216586))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp2 = len(data)\n",
    "X_train, y_train = X_go[:sp], data.category.values[:sp]\n",
    "X_test, y_test = X_go[sp:sp2], data.category.values[sp:sp2]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_weights = (1 / pd.Series(y_train).value_counts()).to_dict() # switching 1 to len(y) seems to make diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = np.vectorize(class_weights.get)(y_train) # * rel_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = data.label_quality.values[sp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 2min 16s, sys: 6min 2s, total: 2h 8min 19s\n",
      "Wall time: 28min 51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/store/tveiga/miniconda3/envs/py/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = sp // 1\n",
    "clf_sgd = SGDClassifier(loss = 'modified_huber', #n_iter = 12,\n",
    "                        max_iter=20, tol=1e-5, # try 1e-6 !!\n",
    "                        alpha = 0.065e-8,\n",
    "#                     early_stopping=True, validation_fraction = .2, n_iter_no_change = 5,\n",
    "                    shuffle = False, n_jobs=4).fit(X_train[:n], y_train[:n],\n",
    "                                                   sample_weight=sample_weight[:n],\n",
    "                                                  )\n",
    "clf = clf_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: 0.8595869215203136\n",
      "Rel: 0.902481976745019\n",
      "CPU times: user 20.2 s, sys: 2.54 s, total: 22.7 s\n",
      "Wall time: 21.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/store/tveiga/miniconda3/envs/py/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prediction_val = clf.predict(X_test)\n",
    "print('Val:', bas(y_test, prediction_val))\n",
    "\n",
    "rel = data.label_quality.values[sp:]\n",
    "print('Rel:', bas(y_test[rel == 0], prediction_val[rel == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Rel:', bas(y_test[rel == 0], prediction_val[rel == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.1 s, sys: 2.33 s, total: 23.5 s\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_proba = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_proba = pd.DataFrame(val_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 47s, sys: 953 ms, total: 2min 48s\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%time val_proba.to_csv('../ensemb3/val_sgd_char-v7_45.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 6min 32s, sys: 6min 58s, total: 2h 13min 31s\n",
      "Wall time: 29min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_data = data.category\n",
    "X_data = X_go[:sp2]\n",
    "class_weights_data = (1 / pd.Series(y_data).value_counts()).to_dict()\n",
    "sample_weight_data = np.vectorize(class_weights_data.get)(y_data)\n",
    "# rel_data =  1 + (1 - data.label_quality.values) * (relfactor - 1)\n",
    "clf.fit(X_data, y_data, sample_weight=sample_weight_data ) # warm start ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proba = clf.predict_proba(X_go[sp2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proba = pd.DataFrame(test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 16s, sys: 728 ms, total: 2min 17s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%time test_proba.to_csv('../ensemb3/test_sgd_char-v7_45.csv', index = False, header = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
