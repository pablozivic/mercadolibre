{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/store/tveiga/miniconda3/envs/py/lib/python3.7/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('../data-simplified-1-reduced-wordbal-800.csv')\n",
    "data = pd.read_csv('../data-reduced-800-v3-shuffled.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcode = pd.read_csv('../data-simplified-1-catcode.csv', header = None, names = ['category'])['category'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "      <th>priorities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>473424</th>\n",
       "      <td>Kit 04 Jogo De Lençol De Berço Em Malha 3 Pcs 100% Algodão</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>6245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519083</th>\n",
       "      <td>Bomba Submersa 450 W Agua Suja Turva Limpa Bsv 450 Vonder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1360</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19488607</th>\n",
       "      <td>Nadador Tiburon Ys1378-5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1155</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16895633</th>\n",
       "      <td>Máscara Angry Birds 6un Imbatível</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1102</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10369454</th>\n",
       "      <td>Aparador Fruteira Madeira De Demolição 1 Gaveta Peroba Rosa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1288</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                title  \\\n",
       "473424     Kit 04 Jogo De Lençol De Berço Em Malha 3 Pcs 100% Algodão   \n",
       "7519083     Bomba Submersa 450 W Agua Suja Turva Limpa Bsv 450 Vonder   \n",
       "19488607                                     Nadador Tiburon Ys1378-5   \n",
       "16895633                            Máscara Angry Birds 6un Imbatível   \n",
       "10369454  Aparador Fruteira Madeira De Demolição 1 Gaveta Peroba Rosa   \n",
       "\n",
       "          label_quality  language  category  priorities  \n",
       "473424                0         1       114        6245  \n",
       "7519083               1         1      1360           4  \n",
       "19488607              1         0      1155          54  \n",
       "16895633              0         1      1102         486  \n",
       "10369454              0         1      1288        1075  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(curr):\n",
    "    # remove accent\n",
    "    curr = curr.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    # to lower case\n",
    "    curr = curr.str.lower()\n",
    "    # remove not alphanumerics or . ,\n",
    "    curr = curr.str.replace('[^a-zA-Z0-9.,]', ' ')\n",
    "    \n",
    "    # let , and . be the same char\n",
    "    curr = curr.str.replace('[.]', ',')\n",
    "    \n",
    "    # remove . , not between numbers\n",
    "    curr = curr.str.replace('(?<=[0-9])[,]+(?=[0-9])', '.')\n",
    "    curr = curr.str.replace('[,]', ' ')\n",
    "    \n",
    "    # set all digits to 0\n",
    "    curr = curr.str.replace('[0-9]', '0')\n",
    "    \n",
    "    # separate ' <digits><letters ' like in 22g or 12ms\n",
    "    # curr = curr.str.replace('(^| )([0-9]+)([a-zA-Z]+)($| )', r'\\1\\2 \\3\\4')\n",
    "    \n",
    "    # remove some Pt plurals\n",
    "    curr = curr.str.replace('\\\\b([a-zA-Z]+[aeiouwy])(s)\\\\b', r'\\1')\n",
    "    \n",
    "    # remove 4 consec (same) letters to just one\n",
    "    curr = curr.str.replace(r'([a-zA-Z])\\1{3,}', r'\\1') # 3 is four? -> three of \\1 after first \\1...\n",
    "    \n",
    "    # separate 4 or more consecutive (different or not) letters\n",
    "    curr = curr.str.replace(r'([a-zA-Z]{4,})', r' \\1 ')\n",
    "    \n",
    "    # Other ideas: \n",
    "    \n",
    "    return curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /store/tveiga/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = lambda w : unicodedata.normalize('NFKD', w).encode('ASCII', 'ignore').decode('ASCII')\n",
    "all_stopw = set()\n",
    "for corpus in ['english', 'portuguese', 'spanish']:\n",
    "    all_stopw.update(set(map(norm, stopwords.words(corpus))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = int(len(data) * 0.8) # Split Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.concat([data[['title']], test[['title']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.9 s, sys: 187 ms, total: 25.1 s\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_full = full.title\n",
    "X_full = normalize(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 s, sys: 628 ms, total: 15.6 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "wordfreq = X_full.str.split(expand=True).stack().value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102942\n",
      "CPU times: user 30.1 ms, sys: 41 µs, total: 30.2 ms\n",
      "Wall time: 30 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "uniquewords = {w for w, f in wordfreq.items() if f == 1}\n",
    "print(len(uniquewords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3906\n"
     ]
    }
   ],
   "source": [
    "testwordfreq = X_full[len(data):].str.split(expand=True).stack().value_counts().to_dict()\n",
    "testuniquewords = {w for w, f in testwordfreq.items() if wordfreq[w] == 1}\n",
    "print(len(testuniquewords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unkn = lambda x : 'U0' if '0' in x else 'UA' # ('UFT' if x in ftwords else 'UA')\n",
    "xjoin = lambda s : ' '.join([w if w not in uniquewords else unkn(w) for w in s ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.73 s, sys: 40.1 ms, total: 3.77 s\n",
      "Wall time: 3.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_full = X_full.str.split().apply(xjoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.74 s, sys: 40 ms, total: 3.78 s\n",
      "Wall time: 3.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xremo = lambda s : ' '.join([w for w in s if w not in all_stopw])\n",
    "X_full = X_full.str.split().apply(xremo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_1gram = X_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 128577) 10776601\n",
      "CPU times: user 8.05 s, sys: 172 ms, total: 8.22 s\n",
      "Wall time: 8.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "covec_1gram = CountVectorizer(binary = True, min_df= 2, lowercase=False,\n",
    "                             ngram_range=(1,1),)\n",
    "X_covec_1gram = covec_1gram.fit_transform(X_full_1gram)\n",
    "print(X_covec_1gram.shape, X_covec_1gram.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfreq1 = np.array(X_covec_1gram.sum(axis = 0)).flatten() / X_covec_1gram.shape[0]\n",
    "inv_vocab1 = {v : k for k,v in covec_1gram.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alto', 'bicicleta', 'bandeja', 'cuero', 'serie', 'silla', 'banco',\n",
       "       'guitarra', 'nueva', 'carro', 'yamaha', 'anti', 'vermelho', 'tubo',\n",
       "       'chave', '00g', 'modulo', 'couro', 'cor', 'philips', 'box',\n",
       "       'branca', 'painel', 'bluetooth', 'eletrico', 'vidrio', 'electrico',\n",
       "       'piso', 'camera', 'freio', 'natural', 'lote', 'radio', 'bivolt',\n",
       "       '000000', 'tapa', 'soporte', 'unid', 'cable', 'cadeira',\n",
       "       'universal', 'entrega', 'controle', 'pc', 'auto', 'renault',\n",
       "       'manual', 'profesional', 'funda', 'lente', 'parede', 'papel', '0v',\n",
       "       'cama', 'mts', 'uso', 'cinta', 'hp', 'peugeot', 'camara', 'alta',\n",
       "       '00w', 'adesivo', 'brinde', '0gb', 'aire', 'gol', 'marca', 'ga',\n",
       "       'premium', 'doble', 'hd', '000mm', 'gel', '00kg', 'ano', 'color',\n",
       "       'protetor', 'blanco', 'plu', 'metal', 'conjunto', 'piscina',\n",
       "       'mascara', 'notebook', '0kg', 'core', 'sony', 'tampa', 'tela',\n",
       "       'samsung', 'eletrica', 'x0', 'ml', 'dvd', '00m', 'combo', 'a0',\n",
       "       '0m', 'roda', 'disco', 'black', 'nuevo', 'preta', 'honda',\n",
       "       'teclado', 'fio', 'vidro', '0d', 'fiat', 'vw', 'tipo', '000g',\n",
       "       'madeira', 'completo', 'verde', 'barra', 'pack', '0000w', 'acero',\n",
       "       'profissional', '0x0', 'plastico', 'aco', 'bola', 'base',\n",
       "       'valvula', 'promocao', 'jogo', 'rosa', 'metro', 'ford', 'par',\n",
       "       'novo', 'sensor', 'negro', 'grande', 'luz', 'tv', 'suporte', 'set',\n",
       "       'moto', 'portatil', 'super', 'caja', '0mm', 'juego', 'cabo',\n",
       "       'madera', 'mm', 'modelo', 'bebe', 'filtro', 'ar', 'capa',\n",
       "       'infantil', 'placa', 'kg', '000w', 'oferta', 'bolsa', 'peca',\n",
       "       'agua', 'aluminio', 'motor', 'pro', 'branco', 'inox', 'bomba',\n",
       "       'usb', 'litro', 'frete', 'caixa', '00v', 'maquina', 'azul',\n",
       "       '00x00', 'envio', '000ml', 'preto', 'digital', 'mini', 'U0',\n",
       "       'bateria', '00mm', '00000', 'grati', '00cm', 'mesa', 'led',\n",
       "       'unidade', 'cm', 'porta', '000v', 'original', 'UA', 'kit', '0000',\n",
       "       '000', '00'], dtype='<U12')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vectorize(inv_vocab1.get)(np.argsort(docfreq1)[-200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01394337, 0.01429093, 0.01489791, 0.01826991, 0.02725018,\n",
       "       0.0476091 , 0.05859951, 0.09254685, 0.10779478, 0.19641812])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(docfreq1)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_2gram = 'SS ' + X_full # + ' EE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 1073510) 8873701\n",
      "CPU times: user 25 s, sys: 308 ms, total: 25.3 s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "covec_2gram = CountVectorizer(binary = True, min_df= 2, lowercase=False,\n",
    "                             ngram_range=(2,2),)\n",
    "X_covec_2gram = covec_2gram.fit_transform(X_full_2gram)\n",
    "print(X_covec_2gram.shape, X_covec_2gram.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfreq2 = np.array(X_covec_2gram.sum(axis = 0)).flatten() / X_covec_2gram.shape[0]\n",
    "inv_vocab2 = {v : k for k,v in covec_2gram.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00 pare', 'SS puerta', 'mercede benz', '00 UA', 'SS globo',\n",
       "       'SS llave', 'SS control', 'SS carro', 'SS impresora', 'aro 00',\n",
       "       'SS entrada', 'kit 000', '000 cm', 'SS flauta', 'SS gel',\n",
       "       'SS polia', 'SS fonte', '00 ano', 'SS taco', 'SS tapete',\n",
       "       'SS adaptador', 'SS colchao', 'SS tinta', 'tp link', 'SS andador',\n",
       "       'SS pintura', 'SS monitor', 'SS amplificador', 'SS leitor',\n",
       "       'SS furadeira', 'SS aparador', 'SS caneta', 'SS roda', 'SS tubo',\n",
       "       'SS oferta', 'SS tabla', 'SS pulseira', 'SS vaso', 'ano 0000',\n",
       "       'ping pong', 'SS cortadora', 'SS ducha', 'SS papel',\n",
       "       'SS aquecedor', 'SS piso', '00 00mm', 'SS cargador', 'SS pileta',\n",
       "       'SS bolso', 'UA 000', '00x00 cm', 'SS garrafa', '00x0 00',\n",
       "       'SS camiseta', '000 000v', 'SS pistola', 'SS cilindro',\n",
       "       '00 pulgada', 'SS campera', 'SS pinza', 'SS chave', 'SS escova',\n",
       "       '00 pcs', 'SS cortina', 'SS camera', 'SS radiador', 'SS 0000',\n",
       "       'SS faca', 'control remoto', 'SS guitarra', 'SS paleta',\n",
       "       'SS mochila', 'SS aceite', 'SS torneira', '00 lts', 'SS tanque',\n",
       "       'SS chaleco', 'SS torno', 'SS cortador', 'SS horno', 'pack 00',\n",
       "       'SS saco', 'audi a0', 'SS bicicleta', 'controle remoto',\n",
       "       '000 litro', 'bomba agua', 'SS detector', 'UA UA', 'SS fita',\n",
       "       'SS reloj', 'SS tapa', 'black decker', 'SS aparelho', 'SS radio',\n",
       "       'SS camisa', 'ar condicionado', 'SS carregador', '000 mm',\n",
       "       'SS sillon', 'SS alicate', 'SS balanca', 'SS lampara', 'SS camara',\n",
       "       'SS antena', 'SS cable', 'SS base', '00 unid', 'SS bota',\n",
       "       'SS banco', 'SS controle', '0000 original', 'SS pedal',\n",
       "       'SS mangueira', 'SS oculo', '000 unidade', 'SS carrinho',\n",
       "       'SS guante', 'SS bandeja', '0000 000', '000 original',\n",
       "       'SS relogio', 'SS dvd', 'filtro ar', 'UA 00', 'SS disco',\n",
       "       'acero inoxidable', 'SS lente', 'SS funda', 'SS colete', 'SS pack',\n",
       "       'SS soporte', 'SS tela', 'SS adesivo', 'SS vendo', 'SS caja',\n",
       "       'SS cama', 'SS painel', 'SS pelota', 'aco inox', 'SS silla',\n",
       "       '00 mts', 'SS luva', 'SS teclado', 'SS barra', '00 metro',\n",
       "       'SS motor', 'SS modulo', '00 peca', 'SS lote', 'SS tampa',\n",
       "       'SS bola', 'SS cinta', 'SS cadeira', 'SS valvula', 'SS cabo',\n",
       "       'pronta entrega', 'SS protetor', 'SS mascara', 'SS par',\n",
       "       'peugeot 000', 'SS 000', 'SS suporte', '00 litro', '00 0000',\n",
       "       'SS set', '000 ml', '00 kg', 'SS conjunto', 'envio grati',\n",
       "       '000 0000', '00 mm', 'SS combo', '0000 00', 'SS jogo', 'SS bolsa',\n",
       "       'SS filtro', 'SS mini', 'SS sensor', 'SS juego', '00 000',\n",
       "       'SS capa', 'SS caixa', 'SS porta', 'SS placa', 'SS UA', '000 00',\n",
       "       '00 unidade', 'SS bomba', 'SS mesa', '000 000', 'SS bateria',\n",
       "       'SS maquina', 'frete grati', 'kit 00', '00 cm', 'SS 00',\n",
       "       '0000 0000', '00 00', 'SS kit'], dtype='<U16')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vectorize(inv_vocab2.get)(np.argsort(docfreq2)[-200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00621157, 0.00703978, 0.00711065, 0.00778295, 0.00959281,\n",
       "       0.00972222, 0.01218281, 0.01652228, 0.0283711 , 0.04596069])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(docfreq2)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 1202087) 19650302\n"
     ]
    }
   ],
   "source": [
    "X_train_counts = sparse.hstack([X_covec_1gram, X_covec_2gram], format = 'csr')\n",
    "print(X_train_counts.shape, X_train_counts.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbc(x):\n",
    "    # sparse binary correlation; x : sparse\n",
    "    # can't correlate zero columns\n",
    "    cx = sparse.triu(x.T*x, k = 1, format='coo')\n",
    "    # print(cx.todense())\n",
    "    card = np.array(x.sum(axis = 0)).flatten()\n",
    "    # print(card)\n",
    "    cx.data = cx.data / (card[cx.row] + card[cx.col] - cx.data)\n",
    "    # print(cx.todense())\n",
    "    return np.array((cx == 1).sum(axis = 0) > 0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08644382644517411\n",
      "CPU times: user 13.8 s, sys: 1.38 s, total: 15.2 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rem = sbc(X_train_counts)\n",
    "print(rem.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 1098174) 19359372\n"
     ]
    }
   ],
   "source": [
    "X_train_counts = X_train_counts[:, ~rem]\n",
    "print(X_train_counts.shape, X_train_counts.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_go = X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 1098174)\n",
      "CPU times: user 256 ms, sys: 39.9 ms, total: 296 ms\n",
      "Wall time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(norm='l2', use_idf=False, smooth_idf=True, sublinear_tf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_go = X_train_tfidf\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1100658, 1098174), (275165, 1098174))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp2 = len(data)\n",
    "X_train, y_train = X_go[:sp], data.category.values[:sp]\n",
    "X_test, y_test = X_go[sp:sp2], data.category.values[sp:sp2]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_weights = (1 / pd.Series(y_train).value_counts()).to_dict() # switching 1 to len(y) seems to make diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = np.vectorize(class_weights.get)(y_train) # * rel_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = data.label_quality.values[sp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.4 s, sys: 22.3 s, total: 1min 14s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = sp // 1\n",
    "clf_mnb = MultinomialNB(alpha = 3e-5, fit_prior=False).fit(X_train[:n], y_train[:n],\n",
    "                                                   sample_weight=sample_weight[:n],\n",
    "                                                              )\n",
    "clf = clf_mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: 0.8502886983706467\n",
      "Rel: 0.8929651006339197\n",
      "CPU times: user 13.9 s, sys: 4.32 s, total: 18.3 s\n",
      "Wall time: 19.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/store/tveiga/miniconda3/envs/py/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prediction_val = clf.predict(X_test)\n",
    "print('Val:', bas(y_test, prediction_val))\n",
    "\n",
    "rel = data.label_quality.values[sp:]\n",
    "print('Rel:', bas(y_test[rel == 0], prediction_val[rel == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 s, sys: 6.6 s, total: 21.2 s\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_proba = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_proba = pd.DataFrame(val_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 15s, sys: 3.19 s, total: 7min 18s\n",
      "Wall time: 7min 28s\n"
     ]
    }
   ],
   "source": [
    "%time val_proba.to_csv('../ensemb3/val_mnb.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = data.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp2 = len(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del X_full\n",
    "# del X_full_1gram\n",
    "# del X_full_2gram\n",
    "# del X_train_counts\n",
    "# del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del clf\n",
    "clf_mnb = MultinomialNB(alpha = 3e-5, fit_prior=False)\n",
    "clf = clf_mnb\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.1 s, sys: 23.1 s, total: 1min 20s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# y_data = data.category\n",
    "X_data = X_go[:sp2]\n",
    "class_weights_data = (1 / pd.Series(y_data).value_counts()).to_dict()\n",
    "sample_weight_data = np.vectorize(class_weights_data.get)(y_data)\n",
    "# rel_data =  1 + (1 - data.label_quality.values) * (relfactor - 1)\n",
    "clf.fit(X_data, y_data, sample_weight=sample_weight_data ) # warm start ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proba = clf.predict_proba(X_go[sp2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proba = pd.DataFrame(test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 16s, sys: 2.89 s, total: 6min 19s\n",
      "Wall time: 6min 28s\n"
     ]
    }
   ],
   "source": [
    "%time test_proba.to_csv('../ensemb3/test_mnb.csv', index = False, header = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
