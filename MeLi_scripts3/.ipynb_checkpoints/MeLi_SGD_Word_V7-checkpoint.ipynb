{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import balanced_accuracy_score as bas\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/store/tveiga/miniconda3/envs/py/lib/python3.7/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('../data-simplified-1-reduced-wordbal-800.csv')\n",
    "data = pd.read_csv('../data-reduced-800-v3-shuffled.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcode = pd.read_csv('../data-simplified-1-catcode.csv', header = None, names = ['category'])['category'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "      <th>priorities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>473424</th>\n",
       "      <td>Kit 04 Jogo De Lençol De Berço Em Malha 3 Pcs 100% Algodão</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>6245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519083</th>\n",
       "      <td>Bomba Submersa 450 W Agua Suja Turva Limpa Bsv 450 Vonder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1360</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19488607</th>\n",
       "      <td>Nadador Tiburon Ys1378-5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1155</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16895633</th>\n",
       "      <td>Máscara Angry Birds 6un Imbatível</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1102</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10369454</th>\n",
       "      <td>Aparador Fruteira Madeira De Demolição 1 Gaveta Peroba Rosa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1288</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                title  \\\n",
       "473424     Kit 04 Jogo De Lençol De Berço Em Malha 3 Pcs 100% Algodão   \n",
       "7519083     Bomba Submersa 450 W Agua Suja Turva Limpa Bsv 450 Vonder   \n",
       "19488607                                     Nadador Tiburon Ys1378-5   \n",
       "16895633                            Máscara Angry Birds 6un Imbatível   \n",
       "10369454  Aparador Fruteira Madeira De Demolição 1 Gaveta Peroba Rosa   \n",
       "\n",
       "          label_quality  language  category  priorities  \n",
       "473424                0         1       114        6245  \n",
       "7519083               1         1      1360           4  \n",
       "19488607              1         0      1155          54  \n",
       "16895633              0         1      1102         486  \n",
       "10369454              0         1      1288        1075  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(curr):\n",
    "    # remove accent\n",
    "    curr = curr.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    # to lower case\n",
    "    curr = curr.str.lower()\n",
    "    # remove not alphanumerics or . ,\n",
    "    curr = curr.str.replace('[^a-zA-Z0-9.,]', ' ')\n",
    "    \n",
    "    # let , and . be the same char\n",
    "    curr = curr.str.replace('[.]', ',')\n",
    "    \n",
    "    # remove . , not between numbers\n",
    "    curr = curr.str.replace('(?<=[0-9])[,]+(?=[0-9])', '.')\n",
    "    curr = curr.str.replace('[,]', ' ')\n",
    "    \n",
    "    # set all digits to 0\n",
    "    curr = curr.str.replace('[0-9]', '0')\n",
    "    \n",
    "    # separate ' <digits><letters ' like in 22g or 12ms\n",
    "    # curr = curr.str.replace('(^| )([0-9]+)([a-zA-Z]+)($| )', r'\\1\\2 \\3\\4')\n",
    "    \n",
    "    # remove some Pt plurals\n",
    "    curr = curr.str.replace('\\\\b([a-zA-Z]+[aeiouwy])(s)\\\\b', r'\\1')\n",
    "    \n",
    "    # remove 4 consec (same) letters to just one\n",
    "    curr = curr.str.replace(r'([a-zA-Z])\\1{3,}', r'\\1') # 3 is four? -> three of \\1 after first \\1...\n",
    "    \n",
    "    # separate 4 or more consecutive (different or not) letters\n",
    "    curr = curr.str.replace(r'([a-zA-Z]{4,})', r' \\1 ')\n",
    "    \n",
    "    # Other ideas: \n",
    "    \n",
    "    return curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /store/tveiga/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = lambda w : unicodedata.normalize('NFKD', w).encode('ASCII', 'ignore').decode('ASCII')\n",
    "all_stopw = set()\n",
    "for corpus in ['english', 'portuguese', 'spanish']:\n",
    "    all_stopw.update(set(map(norm, stopwords.words(corpus))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = int(len(data) * 0.8) # Split Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.concat([data[['title']], test[['title']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.2 s, sys: 236 ms, total: 25.4 s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_full = full.title\n",
    "X_full = normalize(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 649 ms, total: 15.9 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "wordfreq = X_full.str.split(expand=True).stack().value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102942\n",
      "CPU times: user 29.7 ms, sys: 0 ns, total: 29.7 ms\n",
      "Wall time: 29.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "uniquewords = {w for w, f in wordfreq.items() if f == 1}\n",
    "print(len(uniquewords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3906\n"
     ]
    }
   ],
   "source": [
    "testwordfreq = X_full[len(data):].str.split(expand=True).stack().value_counts().to_dict()\n",
    "testuniquewords = {w for w, f in testwordfreq.items() if wordfreq[w] == 1}\n",
    "print(len(testuniquewords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unkn = lambda x : 'U0' if '0' in x else 'UA' # ('UFT' if x in ftwords else 'UA')\n",
    "xjoin = lambda s : ' '.join([w if w not in uniquewords else unkn(w) for w in s ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.07 s, sys: 44 ms, total: 4.11 s\n",
      "Wall time: 4.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_full = X_full.str.split().apply(xjoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.63 s, sys: 20 ms, total: 3.65 s\n",
      "Wall time: 3.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xremo = lambda s : ' '.join([w for w in s if w not in all_stopw])\n",
    "X_full = X_full.str.split().apply(xremo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_1gram = X_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 128577) 10776601\n",
      "CPU times: user 8.76 s, sys: 164 ms, total: 8.92 s\n",
      "Wall time: 8.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "covec_1gram = CountVectorizer(binary = True, min_df= 2, lowercase=False,\n",
    "                             ngram_range=(1,1),)\n",
    "X_covec_1gram = covec_1gram.fit_transform(X_full_1gram)\n",
    "print(X_covec_1gram.shape, X_covec_1gram.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfreq1 = np.array(X_covec_1gram.sum(axis = 0)).flatten() / X_covec_1gram.shape[0]\n",
    "inv_vocab1 = {v : k for k,v in covec_1gram.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alto', 'bicicleta', 'bandeja', 'cuero', 'serie', 'silla', 'banco',\n",
       "       'guitarra', 'nueva', 'carro', 'yamaha', 'anti', 'vermelho', 'tubo',\n",
       "       'chave', '00g', 'modulo', 'couro', 'cor', 'philips', 'box',\n",
       "       'branca', 'painel', 'bluetooth', 'eletrico', 'vidrio', 'electrico',\n",
       "       'piso', 'camera', 'freio', 'natural', 'lote', 'radio', 'bivolt',\n",
       "       '000000', 'tapa', 'soporte', 'unid', 'cable', 'cadeira',\n",
       "       'universal', 'entrega', 'controle', 'pc', 'auto', 'renault',\n",
       "       'manual', 'profesional', 'funda', 'lente', 'parede', 'papel', '0v',\n",
       "       'cama', 'mts', 'uso', 'cinta', 'hp', 'peugeot', 'camara', 'alta',\n",
       "       '00w', 'adesivo', 'brinde', '0gb', 'aire', 'gol', 'marca', 'ga',\n",
       "       'premium', 'doble', 'hd', '000mm', 'gel', '00kg', 'ano', 'color',\n",
       "       'protetor', 'blanco', 'plu', 'metal', 'conjunto', 'piscina',\n",
       "       'mascara', 'notebook', '0kg', 'core', 'sony', 'tampa', 'tela',\n",
       "       'samsung', 'eletrica', 'x0', 'ml', 'dvd', '00m', 'combo', 'a0',\n",
       "       '0m', 'roda', 'disco', 'black', 'nuevo', 'preta', 'honda',\n",
       "       'teclado', 'fio', 'vidro', '0d', 'fiat', 'vw', 'tipo', '000g',\n",
       "       'madeira', 'completo', 'verde', 'barra', 'pack', '0000w', 'acero',\n",
       "       'profissional', '0x0', 'plastico', 'aco', 'bola', 'base',\n",
       "       'valvula', 'promocao', 'jogo', 'rosa', 'metro', 'ford', 'par',\n",
       "       'novo', 'sensor', 'negro', 'grande', 'luz', 'tv', 'suporte', 'set',\n",
       "       'moto', 'portatil', 'super', 'caja', '0mm', 'juego', 'cabo',\n",
       "       'madera', 'mm', 'modelo', 'bebe', 'filtro', 'ar', 'capa',\n",
       "       'infantil', 'placa', 'kg', '000w', 'oferta', 'bolsa', 'peca',\n",
       "       'agua', 'aluminio', 'motor', 'pro', 'branco', 'inox', 'bomba',\n",
       "       'usb', 'litro', 'frete', 'caixa', '00v', 'maquina', 'azul',\n",
       "       '00x00', 'envio', '000ml', 'preto', 'digital', 'mini', 'U0',\n",
       "       'bateria', '00mm', '00000', 'grati', '00cm', 'mesa', 'led',\n",
       "       'unidade', 'cm', 'porta', '000v', 'original', 'UA', 'kit', '0000',\n",
       "       '000', '00'], dtype='<U12')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vectorize(inv_vocab1.get)(np.argsort(docfreq1)[-200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01394337, 0.01429093, 0.01489791, 0.01826991, 0.02725018,\n",
       "       0.0476091 , 0.05859951, 0.09254685, 0.10779478, 0.19641812])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(docfreq1)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_2gram = 'SS ' + X_full + ' EE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 1137791) 10475416\n",
      "CPU times: user 29.2 s, sys: 384 ms, total: 29.6 s\n",
      "Wall time: 28.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "covec_2gram = CountVectorizer(binary = True, min_df= 2, lowercase=False,\n",
    "                             ngram_range=(2,2),)\n",
    "X_covec_2gram = covec_2gram.fit_transform(X_full_2gram)\n",
    "print(X_covec_2gram.shape, X_covec_2gram.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfreq2 = np.array(X_covec_2gram.sum(axis = 0)).flatten() / X_covec_2gram.shape[0]\n",
    "inv_vocab2 = {v : k for k,v in covec_2gram.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SS chave', 'SS escova', '00v EE', 'inox EE', '00 pcs',\n",
       "       'bivolt EE', 'impecable EE', 'SS cortina', 'SS camera',\n",
       "       'pedido EE', '00kg EE', 'excelente EE', 'SS radiador', 'SS 0000',\n",
       "       'SS faca', 'mts EE', 'usb EE', 'regalo EE', 'control remoto',\n",
       "       'preta EE', 'SS guitarra', 'verde EE', 'SS paleta', 'SS mochila',\n",
       "       'SS aceite', '0m EE', 'SS torneira', '00 lts', 'moto EE',\n",
       "       'core EE', 'SS tanque', 'SS chaleco', 'nova EE', 'SS cortador',\n",
       "       'SS torno', 'SS horno', 'pack 00', 'SS saco', 'audi a0',\n",
       "       'SS bicicleta', 'controle remoto', '000 litro', 'bomba agua',\n",
       "       'SS detector', 'nueva EE', 'UA UA', 'SS fita', 'SS reloj',\n",
       "       'SS tapa', 'black decker', 'SS aparelho', '00x00 EE', 'SS radio',\n",
       "       'SS camisa', 'ar condicionado', 'SS carregador', '00m EE',\n",
       "       '000 mm', 'SS sillon', 'SS alicate', 'SS balanca', 'SS lampara',\n",
       "       'SS camara', 'SS antena', 'SS cable', 'SS base', '00 unid',\n",
       "       'mm EE', '00000000 EE', 'SS bota', 'SS banco', 'rosa EE',\n",
       "       'garantia EE', 'SS controle', '0000 original', 'SS pedal',\n",
       "       'SS mangueira', 'negro EE', '0kg EE', 'usado EE', 'SS oculo',\n",
       "       '000 unidade', 'SS carrinho', 'SS guante', 'SS bandeja',\n",
       "       '0000 000', '000 original', 'SS relogio', 'SS dvd', 'filtro ar',\n",
       "       '000000 EE', 'UA 00', 'SS disco', 'acero inoxidable', 'SS lente',\n",
       "       'unid EE', 'SS funda', 'SS colete', 'uso EE', 'SS pack',\n",
       "       'SS soporte', 'SS tela', 'SS adesivo', 'SS vendo', 'metro EE',\n",
       "       'SS caja', 'SS cama', 'SS painel', 'SS pelota', 'aco inox',\n",
       "       'branco EE', 'SS silla', 'ml EE', 'nuevo EE', '00 mts', '00mm EE',\n",
       "       '000g EE', 'SS luva', 'SS teclado', 'SS barra', '00 metro',\n",
       "       'cuota EE', 'SS motor', 'SS modulo', 'entrega EE', '00 peca',\n",
       "       'SS lote', 'SS tampa', 'SS bola', 'SS cinta', 'SS cadeira',\n",
       "       'litro EE', 'novo EE', 'SS valvula', 'azul EE', 'SS cabo', 'kg EE',\n",
       "       'pronta entrega', '00cm EE', 'SS protetor', 'SS mascara', 'SS par',\n",
       "       'peca EE', 'peugeot 000', 'envio EE', 'brinde EE', 'SS 000',\n",
       "       'SS suporte', '00 litro', '00 0000', 'preto EE', 'SS set',\n",
       "       '000 ml', '00 kg', 'SS conjunto', 'envio grati', '000 0000',\n",
       "       '00 mm', 'SS combo', 'U0 EE', '0000 00', 'SS jogo', 'promocao EE',\n",
       "       'SS bolsa', 'SS filtro', 'SS mini', 'SS sensor', 'SS juego',\n",
       "       'cm EE', '00 000', 'SS capa', 'SS caixa', 'oferta EE', '000ml EE',\n",
       "       'SS porta', '00000 EE', 'SS placa', 'SS UA', '000 00',\n",
       "       '00 unidade', 'SS bomba', 'SS mesa', '000 000', 'SS bateria',\n",
       "       'SS maquina', 'frete grati', '000v EE', 'unidade EE', 'kit 00',\n",
       "       'grati EE', '00 cm', 'original EE', 'UA EE', 'SS 00', '0000 0000',\n",
       "       '000 EE', '00 00', '00 EE', '0000 EE', 'SS kit'], dtype='<U16')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vectorize(inv_vocab2.get)(np.argsort(docfreq2)[-200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00972222, 0.01049743, 0.01198439, 0.01218281, 0.01652228,\n",
       "       0.02074221, 0.0283711 , 0.03207709, 0.03661068, 0.04596069])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(docfreq2)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 1266368) 21252017\n"
     ]
    }
   ],
   "source": [
    "X_train_counts = sparse.hstack([X_covec_1gram, X_covec_2gram], format = 'csr')\n",
    "print(X_train_counts.shape, X_train_counts.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbc(x):\n",
    "    # sparse binary correlation; x : sparse\n",
    "    # can't correlate zero columns\n",
    "    cx = sparse.triu(x.T*x, k = 1, format='coo')\n",
    "    # print(cx.todense())\n",
    "    card = np.array(x.sum(axis = 0)).flatten()\n",
    "    # print(card)\n",
    "    cx.data = cx.data / (card[cx.row] + card[cx.col] - cx.data)\n",
    "    # print(cx.todense())\n",
    "    return np.array((cx == 1).sum(axis = 0) > 0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08779596452216101\n",
      "CPU times: user 16.7 s, sys: 1.66 s, total: 18.4 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rem = sbc(X_train_counts)\n",
    "print(rem.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 1155186) 20921274\n"
     ]
    }
   ],
   "source": [
    "X_train_counts = X_train_counts[:, ~rem]\n",
    "print(X_train_counts.shape, X_train_counts.count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_go = X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1622778, 1155186)\n",
      "CPU times: user 303 ms, sys: 43.9 ms, total: 347 ms\n",
      "Wall time: 124 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(norm='l2', use_idf=False, smooth_idf=True, sublinear_tf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_go = X_train_tfidf\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1100658, 1155186), (275165, 1155186))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp2 = len(data)\n",
    "X_train, y_train = X_go[:sp], data.category.values[:sp]\n",
    "X_test, y_test = X_go[sp:sp2], data.category.values[sp:sp2]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_weights = (1 / pd.Series(y_train).value_counts()).to_dict() # switching 1 to len(y) seems to make diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = np.vectorize(class_weights.get)(y_train) # * rel_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = data.label_quality.values[sp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 12min 38s, sys: 5min 54s, total: 1h 18min 33s\n",
      "Wall time: 16min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/store/tveiga/miniconda3/envs/py/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = sp // 1\n",
    "clf_sgd = SGDClassifier(loss = 'modified_huber', #n_iter = 12,\n",
    "                        max_iter=20, tol=1e-5, # try 1e-6 !!\n",
    "                        alpha = 0.065e-8,\n",
    "#                     early_stopping=True, validation_fraction = .2, n_iter_no_change = 5,\n",
    "                    shuffle = False, n_jobs=4).fit(X_train[:n], y_train[:n],\n",
    "                                                   sample_weight=sample_weight[:n],\n",
    "                                                  )\n",
    "clf = clf_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: 0.8648353168144917\n",
      "Rel: 0.9047296235948962\n",
      "CPU times: user 15.7 s, sys: 4.66 s, total: 20.3 s\n",
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/store/tveiga/miniconda3/envs/py/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prediction_val = clf.predict(X_test)\n",
    "print('Val:', bas(y_test, prediction_val))\n",
    "\n",
    "rel = data.label_quality.values[sp:]\n",
    "print('Rel:', bas(y_test[rel == 0], prediction_val[rel == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 s, sys: 4.64 s, total: 20.8 s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_proba = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_proba = pd.DataFrame(val_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 43s, sys: 794 ms, total: 2min 44s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%time val_proba.to_csv('../ensemb3/val_sgd_word-v7.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 29min 48s, sys: 6min 2s, total: 1h 35min 50s\n",
      "Wall time: 21min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_data = data.category\n",
    "X_data = X_go[:sp2]\n",
    "class_weights_data = (1 / pd.Series(y_data).value_counts()).to_dict()\n",
    "sample_weight_data = np.vectorize(class_weights_data.get)(y_data)\n",
    "# rel_data =  1 + (1 - data.label_quality.values) * (relfactor - 1)\n",
    "clf.fit(X_data, y_data, sample_weight=sample_weight_data ) # warm start ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proba = clf.predict_proba(X_go[sp2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proba = pd.DataFrame(test_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 30s, sys: 786 ms, total: 2min 30s\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%time test_proba.to_csv('../ensemb3/test_sgd_word-v7.csv', index = False, header = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
